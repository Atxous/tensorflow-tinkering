{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e844273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "(x_train_full, y_train_full), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "x_train, y_train = x_train_full[:-5000].astype(np.float32), y_train_full[:-5000].astype(np.float32)\n",
    "x_valid, y_valid = x_train_full[-5000:].astype(np.float32), y_train_full[-5000:].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc1fd7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalization(tf.keras.layers.Layer):\n",
    "    def __init__(self, eps = 1e-4, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.eps = eps\n",
    "        \n",
    "    def build(self, batch_input_shape):\n",
    "        self.alpha = self.add_weight(name = \"alpha\", shape = batch_input_shape[-1:], initializer = \"ones\")\n",
    "        self.beta = self.add_weight(name = \"beta\", shape = batch_input_shape[-1:], initializer = \"zeros\")\n",
    "        super().build(batch_input_shape)\n",
    "        \n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return batch_input_shape\n",
    "        \n",
    "    def call(self, x):\n",
    "        mean, variance = tf.nn.moments(x, axes = -1, keepdims = True)\n",
    "        return self.alpha * (x - mean) / (tf.sqrt(variance + self.eps)) + self.beta\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"eps\":self.eps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "918f6e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=3.650889e-06>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_layer_norm = Normalization()\n",
    "keras_layer_norm = tf.keras.layers.LayerNormalization()\n",
    "tf.reduce_mean(tf.keras.losses.mean_absolute_error(keras_layer_norm(x_train), custom_layer_norm(x_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fd34069",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "def data_batch(x, y, batch_size = 32):\n",
    "    ids = np.random.randint(len(x), size = batch_size)\n",
    "    return x[ids], y[ids]\n",
    "\n",
    "def status_bar(step, total, loss, metrics = None):\n",
    "    metrics = \" - \".join([f\"{m.name}:{m.result():.4f}\" for m in [loss] + (metrics or [])])\n",
    "    end = \"\" if step < total else \"\\n\"\n",
    "    print(f\"\\r{step}/{total} - \" + metrics, end = end)\n",
    "\n",
    "regularizer = tf.keras.regularizers.l2(0.01)\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = [28, 28]),\n",
    "    Normalization(),\n",
    "    tf.keras.layers.Dense(32, activation = \"relu\", kernel_initializer = \"he_normal\", kernel_regularizer = regularizer),\n",
    "    tf.keras.layers.Dense(1, kernel_regularizer = regularizer, activation = \"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "020d4aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_epochs = 10\n",
    "batch_size = 32\n",
    "total_steps = len(x_train) // batch_size\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate = 1e-3)\n",
    "loss_fn = tf.keras.losses.sparse_categorical_crossentropy\n",
    "mean_loss = tf.keras.metrics.Mean()\n",
    "metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba8a3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, total_epochs + 1):\n",
    "    print(f\"Epoch {epoch}/{n_epochs}\")\n",
    "    for step in range(1, total_steps + 1):\n",
    "        x_batch, y_batch = data_batch(x_train, y_train)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(x_batch, training = True)\n",
    "            loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            total_loss = tf.add_n([loss] + model.losses)\n",
    "            \n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        \n",
    "        mean_loss(total_loss)\n",
    "        for metric in metrics:\n",
    "            metric(y_batch, y_pred)\n",
    "            \n",
    "        status_bar(step, total_steps, mean_loss, metrics)\n",
    "        \n",
    "    for metric in [mean_loss] + metrics:\n",
    "        metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73c317e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_layers = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = [28, 28]),\n",
    "    Normalization(),\n",
    "    tf.keras.layers.Dense(32, activation = \"relu\", kernel_initializer = \"he_normal\", kernel_regularizer = regularizer)\n",
    "])\n",
    "upper_layers = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(32, activation = \"relu\", kernel_initializer = \"he_normal\", kernel_regularizer = regularizer),\n",
    "    tf.keras.layers.Dense(10, activation = \"softmax\")\n",
    "])\n",
    "model = tf.keras.models.Sequential([\n",
    "    lower_layers, upper_layers\n",
    "])\n",
    "\n",
    "upper_optimizer = tf.keras.optimizers.RMSprop(learning_rate = 1e-3)\n",
    "lower_optimizer = tf.keras.optimizers.Nadam(learning_rate = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef56dd6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e079c81577d44e68937a101f0a0d1b21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "All epochs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e4efab842704838bc76e44fce2be2f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/10:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5107aacfe6104e9da08a0aa4b999f938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/10:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fac98f9059a54b58a8c6ef17bf91122d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/10:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a6037086b89426cadde555bc933bcb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/10:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7a6377fbc464114848e0ecafe570afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/10:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b525d04fd333429c9b7721e7b514f93b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/10:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1712044b91244fca4935da450abf05d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/10:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da552cd9d0848cd8a1c313378f5670a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/10:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deabd17b644b4d9cb85cf4e651557731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/10:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5ab636e7f834defa6e84d8ee737cd40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/10:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import trange\n",
    "from collections import OrderedDict\n",
    "\n",
    "with trange(1, total_epochs + 1, desc = \"All epochs\") as epochs:\n",
    "    for epoch in epochs:\n",
    "        with trange(1, total_steps + 1, desc = f\"Epoch {epoch}/{total_epochs}\") as steps:\n",
    "            for step in steps:\n",
    "                x_batch, y_batch = data_batch(x_train, y_train)\n",
    "                with tf.GradientTape(persistent = True) as tape:\n",
    "                    y_pred = model(x_batch, training = True)\n",
    "                    loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "                    total_loss = tf.add_n([loss] + model.losses)\n",
    "                for layers, optimizer in ((lower_layers, lower_optimizer), (upper_layers, upper_optimizer)):\n",
    "                    gradients = tape.gradient(loss, layers.trainable_variables)\n",
    "                    optimizer.apply_gradients(zip(gradients, layers.trainable_variables))\n",
    "                del tape\n",
    "                for variable in model.variables:\n",
    "                    if variable.constraint is not None:\n",
    "                        variable.assign(variable.constraint(variable))\n",
    "                status = OrderedDict()\n",
    "                mean_loss(total_loss)\n",
    "                status[\"loss\"] = mean_loss.result().numpy()\n",
    "                for metric in metrics:\n",
    "                    metric(y_batch, y_pred)\n",
    "                    status[metric.name] = metric.result().numpy()\n",
    "                steps.set_postfix(status)\n",
    "            y_pred = model(x_valid)\n",
    "            status[\"val_loss\"] = np.mean(loss_fn(y_valid, y_pred))\n",
    "            status[\"val_acc\"] = np.mean(tf.keras.metrics.sparse_categorical_accuracy(tf.constant(y_valid, dtype = np.float32),\n",
    "                                                                                    y_pred))\n",
    "            steps.set_postfix(status)\n",
    "        for metric in [mean_loss] + metrics:\n",
    "            metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1047b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
